==================================================================
 +--------------------------------+
 | Obtain original execution time |
 +--------------------------------+

$ tar -xf openmplab.tar

$ make seq GPROF=1
gcc -o seq  -O2 -pg filter.c main.c func.c util.c -lm

$ ./seq
FUNC TIME : 0.568887
TOTAL TIME : 2.538844

$ gprof seq
Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ms/call  ms/call  name    
 60.43      0.35     0.35       15    23.36    25.27  func1
 25.90      0.50     0.15  5177344     0.00     0.00  rand2
  6.91      0.54     0.04   491520     0.00     0.00  findIndexBin
  3.45      0.56     0.02                             sequence
  1.73      0.57     0.01        1    10.01   131.70  addSeed
  1.73      0.58     0.01        1    10.01    10.01  imdilateDisk
  0.00      0.58     0.00   983042     0.00     0.00  round
  0.00      0.58     0.00       16     0.00     0.00  dilateMatrix
  0.00      0.58     0.00       15     0.00     0.00  func2
  0.00      0.58     0.00       15     0.00     0.00  func3
  0.00      0.58     0.00       15     0.00     0.00  func4
  0.00      0.58     0.00       15     0.00     2.67  func5
  0.00      0.58     0.00       15     0.00     0.00  rand1
  0.00      0.58     0.00        2     0.00     0.00  get_time
  0.00      0.58     0.00        1     0.00     0.00  elapsed_time
  0.00      0.58     0.00        1     0.00     0.00  fillMatrix
  0.00      0.58     0.00        1     0.00     0.00  func0
  0.00      0.58     0.00        1     0.00     0.00  getNeighbors



***RESULT***:

We can see that func1 has the longest execution time, so I decided
to start from modifying func1.

==================================================================
 +-----------+
 | First Try |
 +-----------+

1. Decrease the number of times rand2 being called (func1)
Before:
        for(i = 0; i < n; i++){
          arrayX[i] += 1 + 5*rand2(seed,i);
          arrayY[i] += -2 + 2*rand2(seed,i);
        }
After:
        for(i = 0; i < n; i++){
          double r2 = rand2(seed,i);
          arrayX[i] += 1 + 5*r2;
          arrayY[i] += -2 + 2*r2;
        }

2. Include openmp library
#include “omp.h”

3. Decrease the number of multiplications (func1)
Before:
        for(i = 0; i<n; i++){
          for(j = 0; j < Ones; j++){
            index_X = round(arrayX[i]) + objxy[j*2 + 1];
            index_Y = round(arrayY[i]) + objxy[j*2];
            index[i*Ones + j] = fabs(index_X*Y*Z + index_Y*Z + iter);
            if(index[i*Ones + j] >= max_size)
              index[i*Ones + j] = 0;
          }
          probability[i] = 0;

          for(j = 0; j < Ones; j++) {
            probability[i] += (pow((array[index[i*Ones + j]] - 100),2) -
                           pow((array[index[i*Ones + j]]-228),2))/50.0;
          }
          probability[i] = probability[i]/((double) Ones);
        }
After:
        for(i = 0; i<n; i++){
	  iOnes = i*Ones;
          for(j = 0; j < Ones; j++){
            twoj = j*2;
            index_X = round(arrayX[i]) + objxy[twoj + 1];
            index_Y = round(arrayY[i]) + objxy[twoj];
            index[iOnes + j] = fabs(index_X*Y*Z + index_Y*Z + iter);
            if(index[iOnes + j] >= max_size)
              index[iOnes + j] = 0;
          }
          probability[i] = 0;

          for(j = 0; j < Ones; j++) {
            probability[i] += (pow((array[index[iOnes + j]] - 100),2) -
                           pow((array[index[iOnes + j]]-228),2))/50.0;
          }
          probability[i] = probability[i]/((double) Ones);
        }

4. Parallel loops (func1)
Before:
        for(i = 0; i < n; i++){
		...
        }

        for(i = 0; i<n; i++){
                iOnes = i*Ones;
                for(j = 0; j < Ones; j++){
			...
                }
                ...
        }
After:
        #pragma	omp parallel for private(r2)
        for(i = 0; i < n; i++){
	  r2 = rand2(seed,i);
	  arrayX[i] += 1 + 5*r2;
          arrayY[i] += -2 + 2*r2;

        }

        #pragma	omp parallel for private(iOnes,twoj,index_X,index_Y)
        for(i = 0; i<n; i++){
                iOnes = 0;
                for(j = 0; j < Ones; j++){
			...
                }
		...
        }

5. Combine two loops to improve spacial locality (func2)
Before:
        for(i = 0; i < n; i++)
                weights[i] = weights[i] * exp(probability[i]);

        for(i = 0; i < n; i++)
                sumWeights += weights[i];
After:
#pragma omp parallel for reduction(+:sumWeights)
        for(i = 0; i < n; i++) {
                weights[i] = weights[i] * exp(probability[i]);
                sumWeights += weights[i];
        }

6. Add parallelisms to all the loops in func3, func4, func5

7. Make file
$ make clean
$ make omp
$ ./omp



***RESULT***:

The program hangs.
After trying a lot of things, I finally figured out that the function
rand2(seed,i) cannot be calculated first then used in later functions.
The reason is unclear, but now the program runs successfully.

Execution time:
FUNC TIME : 0.793960
TOTAL TIME : 2.733176

It actually slowed down...

==================================================================
 +------------+
 | Second Try |
 +------------+

1. Use branch prediction (func1)
Before:
	index[iOnes + j] = fabs(index_X*Y*Z + index_Y*Z + iter);
        if(index[iOnes + j] >= max_size)
          index[iOnes + j] = 0;
After:
	value = fabs(index_X*Y*Z + index_Y*Z + iter);
	index[iOnes + j] = (value < max_size) ? value : 0;

2. Specify number of threads (all functions)
#pragma omp parallel for num_threads(10) ...

3. Further decrease number of calculations (func1, func5)
Before:
	weights[i] = 1/((double)(n));
After:
	double nn = 1/((double)(n));
#pragma omp parallel for num_threads(10) firstprivate(nn)
	for (i = 0; i < n; i++) {
		...
		weights[i] = nn;
	}



***RESULT***:

Execution time:
FUNC TIME : 0.203669
TOTAL TIME : 2.024155

Then I tried and tried, but the FUNC TIME stayed around 0.20.

And when I ran:
$ make check
gcc -o omp  -O3 -fopenmp filter.c main.c func.c util.c -lm
cp omp filter
./filter
FUNC TIME : 0.187879
TOTAL TIME : 2.019306
diff --brief correct.txt output.txt
Files correct.txt and output.txt differ
make: *** [Makefile:31: check] Error 1

The output is incorrect.

==================================================================
 +-----------+
 | Third Try |
 +-----------+

1. Make the “value” used in branch prediction to be private
Before:
#pragma omp parallel for num_threads(10) private(i,j,index_X,index_Y,iOnes,twoj,a)
	for(i = 0; i<n; i++) {
		...
		for(j = 0; j < Ones; j++) {
			...
			value = fabs(index_X*Y*Z + index_Y*Z + iter);
			index[iOnes + j] = (value < max_size) ? value : 0;
		}
		...
	}
After:
#pragma omp parallel for num_threads(10) private(i,j,index_X,index_Y,iOnes,value,twoj,a)
	for(i = 0; i<n; i++) {
		...
		for(j = 0; j < Ones; j++) {
			...
			value = fabs(index_X*Y*Z + index_Y*Z + iter);
			index[iOnes + j] = (value < max_size) ? value : 0;
		}
		...
	}

2. Fixed a typo (func3)
Before:
#pragma omp parallel for num_threads(10) reduction(+:estimate_x,estimate_y)
        for(i = 0; i < n; i++){
          estimate_x += arrayX[i] * weights[i];
          estimate_y += arrayX[i] * weights[i];
	}
After:
#pragma omp parallel for num_threads(10) reduction(+:estimate_x,estimate_y)
        for(i = 0; i < n; i++){
          estimate_x += arrayX[i] * weights[i];
          estimate_y += arrayY[i] * weights[i];
	}



***RESULT***:

$ make check
gcc -o omp  -O3 -fopenmp filter.c main.c func.c util.c -lm
cp omp filter
./filter
FUNC TIME : 0.058383
TOTAL TIME : 1.943899
diff --brief correct.txt output.txt

So FUNC TIME is very small, and the output is correct!

==================================================================
 +-------------------+
 | Calculate speedup |
 +-------------------+

Original FUNC TIME, T0 = 0.568887
Modified FUNC TIME, T1 = 0.058383

speedup = T0/T1 = 9.74x

==================================================================

